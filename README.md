# ğŸµ SpotifyBigData - Pipeline ETL Avanzado

> **Pipeline ETL modular y robusto para el procesamiento inteligente de datos musicales de Spotify**

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://python.org)
[![Pandas](https://img.shields.io/badge/Pandas-Latest-green.svg)](https://pandas.pydata.org)
[![ETL](https://img.shields.io/badge/ETL-Pipeline-orange.svg)]()
[![Data Quality](https://img.shields.io/badge/Data%20Quality-Advanced-purple.svg)]()

## ğŸ“‹ Ãndice

- [ğŸ¯ DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [ğŸ—ï¸ Arquitectura del Sistema](#ï¸-arquitectura-del-sistema)
- [ğŸ“ Estructura Detallada](#-estructura-detallada)
- [ğŸ§¹ Sistema de Limpieza de Datos](#-sistema-de-limpieza-de-datos)
- [ğŸ”§ MÃ³dulos y Funcionalidades](#-mÃ³dulos-y-funcionalidades)
- [ğŸ“Š Dataset de Spotify 2023](#-dataset-de-spotify-2023)
- [ğŸš€ GuÃ­a de Uso](#-guÃ­a-de-uso)
- [ğŸ“ˆ Ejemplos de Uso](#-ejemplos-de-uso)
- [ğŸ› ï¸ ConfiguraciÃ³n](#ï¸-configuraciÃ³n)
- [ğŸ” ValidaciÃ³n y Calidad](#-validaciÃ³n-y-calidad)
- [ğŸ“š Referencias](#-referencias)

---

## ğŸ¯ DescripciÃ³n del Proyecto

**SpotifyBigData** es un pipeline ETL (Extract, Transform, Load) de nivel empresarial diseÃ±ado especÃ­ficamente para procesar y analizar datos musicales de Spotify. El proyecto implementa tÃ©cnicas avanzadas de limpieza de datos, validaciÃ³n de calidad y transformaciones inteligentes para convertir datos crudos en informaciÃ³n analÃ­tica de alta calidad.

### ğŸ¨ CaracterÃ­sticas Principales

- **ğŸ”„ Pipeline ETL Modular**: Arquitectura separada y escalable
- **ğŸ§¹ Limpieza Inteligente**: Algoritmos avanzados de detecciÃ³n y correcciÃ³n
- **ğŸ“Š ValidaciÃ³n de Calidad**: Sistema completo de QA para Big Data
- **ğŸµ Especializado en MÃºsica**: Optimizado para datos de plataformas musicales
- **ğŸ“ˆ Reportes Detallados**: AnÃ¡lisis completo del proceso de transformaciÃ³n
- **ğŸ”§ Altamente Configurable**: ParÃ¡metros personalizables para diferentes escenarios

---

## ğŸ—ï¸ Arquitectura del Sistema

El sistema sigue el patrÃ³n **ETL (Extract, Transform, Load)** con una arquitectura modular inspirada en mejores prÃ¡cticas de ingenierÃ­a de datos:

```mermaid
graph TD
    A[ğŸ“ Raw Data CSV] --> B[ğŸ“¥ EXTRACT]
    B --> C[ğŸ”„ TRANSFORM]
    C --> D[ğŸ“¤ LOAD]
    D --> E[ğŸ—„ï¸ SQLite Database]
    D --> F[ğŸ“Š Clean CSV]
    
    C --> G[ğŸ§¹ Data Cleaning]
    C --> H[âœ… Quality Validation]
    C --> I[ğŸ“Š Statistical Analysis]
```

### ğŸ”§ Principios de DiseÃ±o

1. **SeparaciÃ³n de Responsabilidades**: Cada mÃ³dulo tiene una funciÃ³n especÃ­fica
2. **ReutilizaciÃ³n**: Componentes modulares y extensibles
3. **Trazabilidad**: Logging detallado de cada transformaciÃ³n
4. **Escalabilidad**: Optimizado para datasets grandes
5. **Calidad**: ValidaciÃ³n en cada etapa del proceso

---

## ğŸ“ Estructura Detallada

```
SpotifyBigData/
â”œâ”€â”€ ğŸ“‚ app/                           # NÃºcleo de la aplicaciÃ³n ETL
â”‚   â”œâ”€â”€ ğŸ“‚ Config/                    # ğŸ”§ ConfiguraciÃ³n centralizada
â”‚   â”‚   â”œâ”€â”€ __init__.py               # Inicializador del mÃ³dulo
â”‚   â”‚   â””â”€â”€ SMEConfig.py              # Configuraciones globales y rutas
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Extract/                   # ğŸ“¥ MÃ³dulo de extracciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py               # Inicializador del mÃ³dulo
â”‚   â”‚   â”œâ”€â”€ SMExtract.py              # Extractor principal de datos CSV
â”‚   â”‚   â””â”€â”€ ğŸ“‚ Files/                 # ğŸ“ Repositorio de datos
â”‚   â”‚       â”œâ”€â”€ spotify-2023.csv      # Dataset original de Spotify
â”‚   â”‚       â””â”€â”€ etl_data.db           # Base de datos SQLite generada
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ Transform/                 # ğŸ”„ Motor de transformaciÃ³n de datos
â”‚   â”‚   â”œâ”€â”€ __init__.py               # Inicializador del mÃ³dulo
â”‚   â”‚   â””â”€â”€ SMETransform.py           # Sistema avanzado de limpieza
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ Load/                      # ğŸ“¤ MÃ³dulo de carga de datos
â”‚       â”œâ”€â”€ __init__.py               # Inicializador del mÃ³dulo
â”‚       â””â”€â”€ SMEloader.py              # Cargador multi-formato
â”‚
â”œâ”€â”€ ğŸ“‚ data/                          # ğŸ“Š Datos procesados y outputs
â”œâ”€â”€ ğŸ“„ main.py                        # ğŸ¯ Orquestador principal del pipeline
â”œâ”€â”€ ğŸ“„ requirements.txt               # ğŸ“¦ Dependencias del proyecto
â”œâ”€â”€ ğŸ“„ README.md                      # ğŸ“š DocumentaciÃ³n completa
â””â”€â”€ ğŸ“„ .gitignore                     # ğŸš« Exclusiones de Git
```

### ğŸ“‚ DescripciÃ³n de Carpetas

#### ğŸ”§ **Config/** - Centro de ConfiguraciÃ³n
**PropÃ³sito**: Centralizar todas las configuraciones del sistema
- **SMEConfig.py**: Define rutas dinÃ¡micas, parÃ¡metros de base de datos, configuraciones de limpieza
- **Valor**: Facilita mantenimiento y permite cambios sin modificar cÃ³digo

#### ğŸ“¥ **Extract/** - Motor de ExtracciÃ³n
**PropÃ³sito**: Responsable de la lectura y validaciÃ³n inicial de datos
- **SMExtract.py**: Extractor robusto con validaciÃ³n de archivos y manejo de errores
- **Files/**: Repositorio seguro de datos originales y procesados
- **Valor**: Garantiza integridad desde el origen y prepara datos para transformaciÃ³n

#### ğŸ”„ **Transform/** - NÃºcleo de TransformaciÃ³n
**PropÃ³sito**: El corazÃ³n del sistema, donde ocurre la magia de la limpieza
- **SMETransform.py**: Sistema avanzado con 15+ algoritmos de limpieza especializados
- **Valor**: Convierte datos sucios en informaciÃ³n confiable y analizable

#### ğŸ“¤ **Load/** - Sistema de Persistencia
**PropÃ³sito**: Almacenamiento inteligente en mÃºltiples formatos
- **SMEloader.py**: Cargador con validaciÃ³n, respaldo y mÃºltiples destinos
- **Valor**: Asegura que los datos limpios estÃ©n disponibles para anÃ¡lisis

---

## ğŸ§¹ Sistema de Limpieza de Datos

### ğŸ¯ Â¿Por QuÃ© es Crucial la Limpieza de Datos?

En el mundo del anÃ¡lisis de datos musicales, la **calidad de los datos determina la calidad de los insights**. Nuestro sistema de limpieza aborda:

- **ğŸµ Streams inconsistentes**: Valores no numÃ©ricos en columnas de reproducciones
- **ğŸ“… Fechas malformadas**: AÃ±os, meses, dÃ­as con formatos incorrectos
- **ğŸ“Š Porcentajes corruptos**: CaracterÃ­sticas musicales con valores invÃ¡lidos
- **ğŸ”¢ Campos mixtos**: Columnas que mezclan texto y nÃºmeros
- **âŒ Valores faltantes**: Datos incompletos que comprometen el anÃ¡lisis

### ğŸ› ï¸ MetodologÃ­a de Limpieza Avanzada

#### 1. **ğŸ“Š AnÃ¡lisis Exploratorio Inicial**
```python
# Ejemplo de anÃ¡lisis automÃ¡tico
cleaner = DataClean(df)
analysis = cleaner.analyze_null_values()
# Reporta: total de nulos, porcentajes, columnas afectadas
```

#### 2. **ğŸµ Limpieza Especializada por Tipo de Columna**

##### **Columnas NumÃ©ricas EspecÃ­ficas de Spotify:**
- `streams` - NÃºmero de reproducciones
- `bpm` - Beats por minuto
- `danceability_%`, `valence_%`, `energy_%` - CaracterÃ­sticas musicales
- `in_spotify_playlists`, `in_apple_charts` - Presencia en plataformas

**Proceso de Limpieza:**
1. **DetecciÃ³n Inteligente**: Identifica columnas que deberÃ­an ser numÃ©ricas
2. **SanitizaciÃ³n**: Remueve caracteres especiales (`,`, `$`, `%`)
3. **ConversiÃ³n Robusta**: `pd.to_numeric(errors='coerce')`
4. **ImputaciÃ³n EstadÃ­stica**: Reemplaza valores invÃ¡lidos con la mediana
5. **ValidaciÃ³n Final**: Confirma que solo existan valores numÃ©ricos vÃ¡lidos

##### **Columnas de Texto/CategÃ³ricas:**
- `track_name`, `artist_name` - InformaciÃ³n del artista
- `key`, `mode` - CaracterÃ­sticas musicales categÃ³ricas

**Proceso de Limpieza:**
1. **NormalizaciÃ³n**: Estandariza espacios y capitalizaciÃ³n
2. **ImputaciÃ³n por Moda**: Rellena valores faltantes con el valor mÃ¡s frecuente
3. **ValidaciÃ³n de Consistencia**: Verifica formatos esperados

#### 3. **ğŸ” DetecciÃ³n y EliminaciÃ³n de Duplicados**
```python
# Algoritmo inteligente de duplicados
dup_info = cleaner.remove_duplicates()
# Retorna: cantidad removida, porcentaje, estrategia aplicada
```

#### 4. **ğŸ“ˆ DetecciÃ³n de Valores AtÃ­picos (Outliers)**
```python
# MÃ©todo IQR (Rango IntercuartÃ­lico)
outlier_info = cleaner.remove_unwanted_values(remove_outliers=True)
# Identifica y trata valores estadÃ­sticamente atÃ­picos
```

#### 5. **âœ… Control de Calidad (QA) para Big Data**
```python
# Sistema completo de QA
qa_report = cleaner.quality_assessment()
# Genera: score de calidad, completitud, unicidad, recomendaciones
```

### ğŸ“Š Algoritmos de ImputaciÃ³n

#### **Para Datos NumÃ©ricos: Mediana**
**Â¿Por quÃ© Mediana y no Media?**
- **Robustez ante Outliers**: La mediana no se ve afectada por valores extremos
- **Datos Musicales**: En mÃºsica, valores como BPM o reproducciones pueden tener outliers naturales
- **PreservaciÃ³n de DistribuciÃ³n**: Mantiene mejor las caracterÃ­sticas estadÃ­sticas originales

```python
# Ejemplo: Columna 'streams' con valores atÃ­picos
streams_original = [1000, 1200, 1500, 999999999, 1100]  # 999M es outlier
median_value = 1200  # No afectada por el outlier
mean_value = 200002560  # Distorsionada por el outlier
```

#### **Para Datos CategÃ³ricos: Moda**
**Â¿Por quÃ© Moda?**
- **Preserva DistribuciÃ³n Natural**: Mantiene las frecuencias originales
- **LÃ³gica Musical**: En datos de mÃºsica, ciertos gÃ©neros o claves son mÃ¡s comunes
- **Consistencia SemÃ¡ntica**: No introduce valores artificiales

---

## ğŸ”§ MÃ³dulos y Funcionalidades

### ğŸ“¥ **Extract/SMExtract.py** - Extractor Inteligente

#### **Clase Principal: `SpotifyExtractor`**

**Funcionalidades Avanzadas:**
- **ğŸ” ValidaciÃ³n de Archivos**: Verifica existencia, permisos y formato
- **ğŸ“Š Metadatos AutomÃ¡ticos**: Extrae informaciÃ³n del archivo (tamaÃ±o, fecha)
- **ğŸ›¡ï¸ Manejo de Errores**: Captura y reporta problemas de lectura
- **ğŸ’¾ OptimizaciÃ³n de Memoria**: Configuraciones para datasets grandes

**MÃ©todos Principales:**
```python
extractor = SpotifyExtractor('path/to/spotify.csv')

# ExtracciÃ³n bÃ¡sica
data = extractor.extract_data()

# Vista previa sin cargar todo
preview = extractor.get_preview(n_rows=10)

# InformaciÃ³n detallada del archivo
info = extractor.get_data_info()

# ExtracciÃ³n + limpieza en un paso
clean_data = extractor.extract_and_clean()
```

### ğŸ”„ **Transform/SMETransform.py** - Motor de TransformaciÃ³n

#### **Clase Principal: `DataClean`**

**Sistema Modular de Limpieza:**

##### **ğŸµ MÃ©todos Especializados para Spotify:**
- `clean_specific_numeric_columns()`: Procesa las 20 columnas numÃ©ricas especÃ­ficas
- `analyze_streams_column()`: AnÃ¡lisis especializado de la columna 'streams'
- `validate_specific_numeric_columns()`: ValidaciÃ³n de columnas musicales

##### **ğŸ§¹ MÃ©todos Generales de Limpieza:**
- `remove_duplicates()`: EliminaciÃ³n inteligente de duplicados
- `handle_missing_data()`: Estrategias mÃºltiples para datos faltantes
- `remove_unwanted_values()`: DetecciÃ³n y tratamiento de outliers
- `quality_assessment()`: EvaluaciÃ³n completa de calidad

##### **ğŸ“Š MÃ©todos de AnÃ¡lisis:**
- `analyze_null_values()`: AnÃ¡lisis detallado de valores faltantes
- `get_cleaning_summary()`: Resumen completo del proceso
- `print_quality_report()`: Reporte legible de calidad

**Flujo de TransformaciÃ³n Completo:**
```python
cleaner = DataClean(raw_data)

# Proceso completo automatizado
results = cleaner.comprehensive_clean(
    remove_duplicates=True,
    handle_missing=True,
    remove_unwanted=True,
    run_qa=True
)

# ValidaciÃ³n especÃ­fica de Spotify
validation = cleaner.validate_specific_numeric_columns()

# Datos finales limpios
clean_data = cleaner.get_cleaned_data()
```

### ğŸ“¤ **Load/SMEloader.py** - Cargador Multi-formato

#### **Clase Principal: `Loader`**

**Capacidades de Carga:**
- **ğŸ—„ï¸ SQLite**: Base de datos local optimizada
- **ğŸ“„ CSV**: Formato estÃ¡ndar para anÃ¡lisis
- **ğŸ“‹ JSON**: Formato para APIs y aplicaciones web
- **ğŸ”„ Multi-formato**: Carga simultÃ¡nea en varios destinos

**CaracterÃ­sticas Avanzadas:**
- **âœ… ValidaciÃ³n Pre-carga**: Verifica integridad antes de guardar
- **ğŸ”„ Respaldos AutomÃ¡ticos**: Preserva versiones anteriores
- **ğŸ“Š MÃ©tricas de Performance**: Reporta tiempos y tamaÃ±os
- **ğŸ›¡ï¸ Manejo de Errores**: Rollback en caso de fallos

---

## ğŸ“Š Dataset de Spotify 2023

### ğŸµ DescripciÃ³n del Dataset

El dataset **"Most Streamed Spotify Songs 2023"** contiene informaciÃ³n detallada sobre las canciones mÃ¡s populares en Spotify durante 2023.

### ğŸ“‹ Estructura de Datos (24 Columnas)

#### **ğŸ¤ InformaciÃ³n BÃ¡sica de la CanciÃ³n**
- `track_name`: Nombre de la canciÃ³n
- `artist_name`: Nombre del artista
- `artist_count`: NÃºmero de artistas colaboradores

#### **ğŸ“… InformaciÃ³n de Lanzamiento**
- `released_year`: AÃ±o de lanzamiento
- `released_month`: Mes de lanzamiento
- `released_day`: DÃ­a de lanzamiento

#### **ğŸ“Š MÃ©tricas de Popularidad**
- `streams`: NÃºmero total de reproducciones
- `in_spotify_playlists`: Presencia en playlists de Spotify
- `in_spotify_charts`: PosiciÃ³n en charts de Spotify

#### **ğŸ§ Presencia en Otras Plataformas**
- `in_apple_playlists`: Presencia en Apple Music
- `in_apple_charts`: PosiciÃ³n en charts de Apple
- `in_deezer_playlists`: Presencia en Deezer
- `in_deezer_charts`: PosiciÃ³n en charts de Deezer
- `in_shazam_charts`: Presencia en Shazam

#### **ğŸ¼ CaracterÃ­sticas Musicales**
- `bpm`: Beats por minuto (tempo)
- `key`: Clave musical (C, C#, D, etc.)
- `mode`: Modo musical (Major/Minor)

#### **ğŸ¨ Atributos de Audio (%)**
- `danceability_%`: QuÃ© tan bailable es la canciÃ³n
- `valence_%`: Positividad musical (feliz/triste)
- `energy_%`: Intensidad y poder de la canciÃ³n
- `acousticness_%`: Nivel de instrumentos acÃºsticos
- `instrumentalness_%`: Ausencia de vocales
- `liveness_%`: Presencia de audiencia en vivo
- `speechiness_%`: Presencia de palabras habladas

### ğŸ” DesafÃ­os de Calidad en el Dataset

1. **ğŸµ Columna 'streams'**: Valores no numÃ©ricos mezclados con nÃºmeros
2. **ğŸ“… Fechas inconsistentes**: Formatos variables en fecha de lanzamiento
3. **ğŸ“Š Porcentajes corruptos**: CaracterÃ­sticas musicales con valores invÃ¡lidos
4. **ğŸ”¢ Campos mixtos**: Columnas numÃ©ricas con texto
5. **âŒ Valores faltantes**: Datos incompletos en varias columnas

**Nuestro sistema ETL aborda cada uno de estos desafÃ­os con algoritmos especializados.**

---

## ğŸš€ GuÃ­a de Uso

### ğŸ“¦ InstalaciÃ³n y ConfiguraciÃ³n

#### **1. Clonar el Repositorio**
```bash
git clone https://github.com/Sebastianfandi24/SpotifyBigData.git
cd SpotifyBigData
```

#### **2. Instalar Dependencias**
```bash
pip install -r requirements.txt
```

#### **3. Verificar Estructura**
```bash
python -c "import pandas as pd; print('âœ… Pandas instalado correctamente')"
```

### ğŸ¯ EjecuciÃ³n BÃ¡sica

#### **Ejecutar Pipeline Completo**
```bash
python3 main.py
```

**Salida Esperada:**
```
Datos nulos en el CSV original:
track_name               0
artist_name              0
streams                 50
bpm                     20
...

=== ANÃLISIS DE VALORES NULOS ===
Total de filas: 953
Total de columnas: 24
Total de valores nulos: 95

ğŸµ Limpiando columnas numÃ©ricas especÃ­ficas de Spotify...
ğŸ¯ Procesando 20 columnas especÃ­ficas...

âœ… streams: 50 valores rellenados con mediana: 141,625,465
âœ… bpm: 20 valores rellenados con mediana: 120.00
...

=== RESUMEN DE LIMPIEZA ===
{'original_shape': (953, 24), 'current_shape': (953, 24), 'rows_removed': 0, 'columns_removed': 0}

Datos guardados en la base de datos SQLite
```

---

## ğŸ“ˆ Ejemplos de Uso

### ğŸ”§ **Uso BÃ¡sico - Pipeline AutomÃ¡tico**
```python
from app.Extract.SMExtract import SpotifyExtractor
from app.Transform.SMETransform import DataClean
from app.Load.SMEloader import Loader

# Pipeline automÃ¡tico
def basic_etl():
    # Extract
    extractor = SpotifyExtractor('app/Extract/Files/spotify-2023.csv')
    raw_data = extractor.extract_data()
    
    # Transform
    cleaner = DataClean(raw_data)
    clean_data = cleaner.clean_data()
    
    # Load
    loader = Loader(clean_data)
    loader.to_sqlite()
    
    return clean_data
```

### ğŸµ **AnÃ¡lisis EspecÃ­fico de Columnas Musicales**
```python
def analyze_music_features():
    # Cargar y limpiar datos
    extractor = SpotifyExtractor('app/Extract/Files/spotify-2023.csv')
    raw_data = extractor.extract_data()
    
    cleaner = DataClean(raw_data)
    
    # AnÃ¡lisis especÃ­fico de 'streams'
    streams_analysis = cleaner.analyze_streams_column()
    print(f"Pureza numÃ©rica de streams: {streams_analysis['data_quality']['numeric_percentage']:.1f}%")
    
    # Limpiar columnas especÃ­ficas
    cleaning_summary = cleaner.clean_specific_numeric_columns()
    
    # Validar resultado
    validation = cleaner.validate_specific_numeric_columns()
    print(f"ValidaciÃ³n exitosa: {validation['overall_status']}")
    
    return cleaner.get_cleaned_data()
```

### ğŸ“Š **Control de Calidad Avanzado**
```python
def quality_assessment():
    extractor = SpotifyExtractor('app/Extract/Files/spotify-2023.csv')
    raw_data = extractor.extract_data()
    
    cleaner = DataClean(raw_data)
    
    # Proceso completo con QA
    results = cleaner.comprehensive_clean(
        remove_duplicates=True,
        handle_missing=True,
        remove_unwanted=True,
        run_qa=True
    )
    
    # Reporte de calidad
    cleaner.print_quality_report()
    
    # EstadÃ­sticas especÃ­ficas
    stats = cleaner.get_numeric_columns_summary()
    
    return results, stats
```

### ğŸ”„ **Carga Multi-formato**
```python
def multi_format_export():
    # Obtener datos limpios
    clean_data = basic_etl()
    
    # Cargador con validaciÃ³n
    loader = Loader(clean_data)
    
    # Validar antes de cargar
    if loader.validate_data(strict=True):
        # Cargar en mÃºltiples formatos
        results = loader.load_all(
            base_path='output/spotify_clean',
            formats=['csv', 'sqlite', 'json']
        )
        
        # Mostrar resumen
        loader.print_load_summary()
        
        return results
    else:
        print("âŒ Datos no pasaron validaciÃ³n")
        return None
```

---

## ğŸ› ï¸ ConfiguraciÃ³n

### âš™ï¸ **Config/SMEConfig.py** - Centro de Control

```python
class Config:
    # Rutas de archivos
    INPUT_PATH = 'app/Extract/Files/spotify-2023.csv'
    SQLITE_DB_PATH = 'app/Extract/Files/etl_data.db'
    SQLITE_TABLE = 'spotify_data_clean'
    
    # Configuraciones de limpieza
    CLEANING_PARAMS = {
        'remove_duplicates': True,
        'handle_missing': True,
        'remove_unwanted': True,
        'missing_threshold': 0.5,
        'outlier_method': 'iqr'
    }
    
    # InformaciÃ³n del dataset
    DATASET_INFO = {
        'name': 'Spotify Tracks 2023',
        'expected_columns': 24,
        'expected_rows': 953
    }
```

### ğŸ”§ ParÃ¡metros Configurables

#### **Limpieza de Datos:**
- `missing_threshold`: Umbral para eliminar columnas (% de nulos)
- `outlier_method`: MÃ©todo de detecciÃ³n de outliers ('iqr', 'zscore')
- `fill_strategy`: Estrategia de relleno ('median', 'mean', 'mode')

#### **Base de Datos:**
- `if_exists`: Comportamiento al cargar ('replace', 'append', 'fail')
- `index`: Si guardar Ã­ndice como columna
- `method`: MÃ©todo de inserciÃ³n para optimizaciÃ³n

#### **Logging:**
- `log_level`: Nivel de detalle ('DEBUG', 'INFO', 'WARNING', 'ERROR')
- `log_file`: Archivo de logs del proceso
- `max_log_size`: TamaÃ±o mÃ¡ximo de archivos de log

---

## ğŸ” ValidaciÃ³n y Calidad

### ğŸ“Š **MÃ©tricas de Calidad Implementadas**

#### **1. Score de Completitud**
```python
completeness_score = (total_cells - null_cells) / total_cells * 100
```

#### **2. Score de Unicidad**
```python
uniqueness_ratio = unique_values / total_values
```

#### **3. Score General de Calidad**
```python
quality_score = (
    completeness_score * 0.4 +      # 40% completitud
    purity_score * 0.3 +             # 30% pureza de tipos
    consistency_score * 0.3          # 30% consistencia
)
```

### âœ… **Validaciones Implementadas**

1. **Integridad de Tipos**: Verifica que columnas numÃ©ricas solo contengan nÃºmeros
2. **Rangos VÃ¡lidos**: Valida que valores estÃ©n en rangos esperados
3. **Consistencia Temporal**: Verifica fechas lÃ³gicas
4. **Completitud**: Asegura ausencia de valores crÃ­ticos faltantes
5. **Unicidad**: Detecta y maneja duplicados

### ğŸ“‹ **Reportes de Calidad**

```python
# Ejemplo de reporte automÃ¡tico
{
    'overall_quality_score': 94.5,
    'completeness': {
        'total_nulls': 0,
        'null_percentage': 0.0,
        'completeness_score': 100.0
    },
    'recommendations': [
        'Los datos tienen buena calidad general',
        'Se recomienda monitorear outliers en BPM'
    ]
}
```

---

## ğŸ“š Referencias

### ğŸ”— **Datasets y Fuentes**
- [Spotify Most Streamed Songs 2023](https://www.kaggle.com/datasets/nelgiriyewithana/top-spotify-songs-2023) - Dataset original
- [Spotify Web API](https://developer.spotify.com/documentation/web-api/) - DocumentaciÃ³n oficial
- [Music Information Retrieval](https://musicinformationretrieval.com/) - Conceptos musicales

### ğŸ“– **MetodologÃ­as y Mejores PrÃ¡cticas**
- [ETL Best Practices](https://www.kimballgroup.com/) - MetodologÃ­a Kimball
- [Data Quality Framework](https://tdwi.org/) - TDWI Data Quality
- [Pandas Data Cleaning](https://pandas.pydata.org/docs/) - DocumentaciÃ³n oficial

### ğŸ› ï¸ **Herramientas y TecnologÃ­as**
- [Pandas](https://pandas.pydata.org/) - ManipulaciÃ³n de datos
- [NumPy](https://numpy.org/) - ComputaciÃ³n numÃ©rica
- [SQLite](https://www.sqlite.org/) - Base de datos embebida

---

## ğŸ¤ ContribuciÃ³n

### ğŸ“‹ **GuÃ­as de ContribuciÃ³n**
1. Fork el repositorio
2. Crea una rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -am 'Agrega nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

### ğŸ”§ **EstÃ¡ndares de CÃ³digo**
- **PEP 8**: Estilo de cÃ³digo Python
- **Docstrings**: DocumentaciÃ³n completa de funciones
- **Type Hints**: Anotaciones de tipos cuando sea posible
- **Testing**: Pruebas unitarias para nuevas funcionalidades

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver el archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¨â€ğŸ’» Autor

**SebastiÃ¡n FandiÃ±o**
- GitHub: [@Sebastianfandi24](https://github.com/Sebastianfandi24)
- Email: [sebastianfandi24@example.com]

---

## ğŸ”„ Changelog

### v2.0.0 (Septiembre 2025)
- âœ… Sistema avanzado de limpieza de columnas especÃ­ficas
- âœ… ValidaciÃ³n inteligente de datos musicales
- âœ… Control de calidad para Big Data
- âœ… Reportes detallados y mÃ©tricas de performance
- âœ… DocumentaciÃ³n completa y ejemplos

### v1.0.0 (Inicial)
- âœ… Pipeline ETL bÃ¡sico
- âœ… Limpieza general de datos
- âœ… Carga a SQLite
- âœ… Estructura modular

---

<div align="center">

**ğŸµ Transformando datos musicales en insights de valor ğŸµ**

[![Made with â¤ï¸](https://img.shields.io/badge/Made%20with-â¤ï¸-red.svg)]()
[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://python.org)
[![ETL](https://img.shields.io/badge/ETL-Pipeline-green.svg)]()

</div>

## DescripciÃ³n de cada mÃ³dulo

- **Config/SMEConfig.py**: Define rutas y parÃ¡metros globales para el pipeline.
- **Extract/SMExtract.py**: Lee el archivo CSV y lo carga en un DataFrame usando pandas.
- **Transform/SMETransform.py**: Limpia los datos usando la clase `DataClean`, que analiza valores nulos y los rellena con mediana (numÃ©ricos) o moda (categÃ³ricos). TambiÃ©n genera un resumen de limpieza y calidad de datos.
- **Load/SMEloader.py**: Prepara los datos limpios para su uso o exportaciÃ³n.
- **main.py**: Ejecuta el flujo ETL completo, mostrando anÃ¡lisis de nulos, resumen de limpieza y los primeros 5 registros limpios.

## Proceso de limpieza de datos


## Proceso detallado de limpieza y llenado de datos

La limpieza de datos se realiza en el mÃ³dulo `Transform/SMETransform.py` mediante la clase `DataClean`. El proceso sigue estos pasos:

1. **AnÃ¡lisis de valores nulos**
  - Se identifican todas las columnas que contienen valores nulos.
  - Se calcula el nÃºmero y porcentaje de valores nulos por columna.
  - Se genera un reporte con el total de filas, columnas, columnas afectadas y el porcentaje de nulos.

2. **Llenado de valores nulos**
  - **Columnas numÃ©ricas:**  Los valores nulos se rellenan usando la mediana de cada columna. Esto ayuda a evitar que valores extremos (outliers) afecten el resultado, ya que la mediana es menos sensible a ellos que la media.
  - **Columnas categÃ³ricas (no numÃ©ricas):**  Los valores nulos se rellenan usando la moda (el valor mÃ¡s frecuente) de cada columna. Esto asegura que los datos faltantes se completan con el valor mÃ¡s representativo de la columna.

3. **Resumen de limpieza**
  - Se calcula la forma original y final del DataFrame (filas y columnas).
  - Se reporta cuÃ¡ntos valores nulos quedan tras la limpieza (deberÃ­a ser cero si todas las columnas fueron tratadas).
  - Se calcula un â€œscore de calidad de datosâ€, que representa el porcentaje de datos no nulos tras la limpieza.

4. **VisualizaciÃ³n y validaciÃ³n**
  - El pipeline muestra en consola el anÃ¡lisis de nulos antes de limpiar, el resumen de limpieza y los primeros 5 registros limpios para validar el resultado.

### Ejemplo de cÃ³digo usado para limpiar los datos

```python
# Rellenar valores faltantes con la mediana en columnas numÃ©ricas
numeric_columns = df.select_dtypes(include=[np.number]).columns
for col in numeric_columns:
   df[col] = df[col].fillna(df[col].median())

# Rellenar valores faltantes con la moda en columnas no numÃ©ricas
non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns
for col in non_numeric_columns:
   most_frequent = df[col].mode()
   if len(most_frequent) > 0:
      df[col] = df[col].fillna(most_frequent[0])
```

## ConfiguraciÃ³n y dependencias

Instala las dependencias usando:
```sh
pip install -r requirements.txt
```

Principales librerÃ­as usadas:
- pandas
- numpy

## EjecuciÃ³n del pipeline

Ejecuta el pipeline desde la raÃ­z del proyecto:
```sh
python3 main.py
```

## Pruebas

- Verifica que el archivo `app/Extract/Files/spotify-2023.csv` exista y tenga datos.
- Al ejecutar `main.py`, se debe mostrar:
  - AnÃ¡lisis de valores nulos
  - Resumen de limpieza
  - 5 registros limpios
- Si hay errores de importaciÃ³n, revisa que las rutas sean correctas y que las dependencias estÃ©n instaladas.

## Recomendaciones

- MantÃ©n actualizado el archivo `requirements.txt` usando `pip freeze > requirements.txt`.
- Usa ramas Feature para nuevas funcionalidades y Release para preparar versiones de producciÃ³n.
- Documenta cualquier cambio importante en el README.md.

## Autor
- SebastiÃ¡n FandiÃ±o
